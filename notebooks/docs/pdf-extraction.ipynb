{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12833282,"sourceType":"datasetVersion","datasetId":8101888}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pymupdf pdfplumber pytesseract pillow langchain sentence-transformers regex langdetect qdrant-client","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-22T05:58:57.945440Z","iopub.execute_input":"2025-08-22T05:58:57.945720Z","iopub.status.idle":"2025-08-22T06:00:26.505194Z","shell.execute_reply.started":"2025-08-22T05:58:57.945696Z","shell.execute_reply":"2025-08-22T06:00:26.504467Z"}},"outputs":[{"name":"stdout","text":"Collecting pymupdf\n  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\nCollecting pdfplumber\n  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\nRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\nCollecting langdetect\n  Downloading langdetect-1.0.9.tar.gz (981 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting qdrant-client\n  Downloading qdrant_client-1.15.1-py3-none-any.whl.metadata (11 kB)\nCollecting pdfminer.six==20250506 (from pdfplumber)\n  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (44.0.3)\nRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (25.0)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.66)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\nRequirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.4)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.1)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\nRequirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (1.73.1)\nRequirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\nRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (1.26.4)\nCollecting portalocker<4.0,>=2.7.0 (from qdrant-client)\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (3.20.3)\nRequirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.5.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\nRequirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.5.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\nCollecting packaging>=21.3 (from pytesseract)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\nRequirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\nRequirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->qdrant-client) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->qdrant-client) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21->qdrant-client) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21->qdrant-client) (2024.2.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21->qdrant-client) (2024.2.0)\nDownloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading qdrant_client-1.15.1-py3-none-any.whl (337 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.3/337.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: langdetect\n  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=edf5f98cff4d4c955fb677c4d095cc0f26477e4c6ad7b10d9922e84b2cfbddbb\n  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\nSuccessfully built langdetect\nInstalling collected packages: pypdfium2, pymupdf, portalocker, packaging, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, langdetect, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pdfminer.six, nvidia-cusolver-cu12, pdfplumber, qdrant-client\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langdetect-1.0.9 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 packaging-24.2 pdfminer.six-20250506 pdfplumber-0.11.7 portalocker-3.2.0 pymupdf-1.26.3 pypdfium2-4.30.0 qdrant-client-1.15.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install langchain-community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T06:00:26.506680Z","iopub.execute_input":"2025-08-22T06:00:26.506914Z","iopub.status.idle":"2025-08-22T06:00:36.919481Z","shell.execute_reply.started":"2025-08-22T06:00:26.506892Z","shell.execute_reply":"2025-08-22T06:00:36.918781Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain-community\n  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.66)\nRequirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.26)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.4)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.13)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2.4.1)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.6.15)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain-community) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\nDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\nDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nInstalling collected packages: python-dotenv, httpx-sse, pydantic-settings, langchain-community\nSuccessfully installed httpx-sse-0.4.1 langchain-community-0.3.27 pydantic-settings-2.10.1 python-dotenv-1.1.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport fitz  # PyMuPDF\nimport pdfplumber\nimport pytesseract\nfrom PIL import Image\nimport json\nfrom langchain.schema import Document\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_community.vectorstores import Qdrant\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.http import models\nimport regex as re\nfrom langdetect import detect\nimport unicodedata\nprint(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T06:00:36.922971Z","iopub.execute_input":"2025-08-22T06:00:36.923569Z","iopub.status.idle":"2025-08-22T06:00:39.961694Z","shell.execute_reply.started":"2025-08-22T06:00:36.923537Z","shell.execute_reply":"2025-08-22T06:00:39.960976Z"}},"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from datetime import datetime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T06:31:38.411606Z","iopub.execute_input":"2025-08-22T06:31:38.411931Z","iopub.status.idle":"2025-08-22T06:31:38.415709Z","shell.execute_reply.started":"2025-08-22T06:31:38.411907Z","shell.execute_reply":"2025-08-22T06:31:38.414866Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"PDF_DIR = \"/kaggle/input/my-pdfs\"           # letakkan PDF disini\nOUT_JSON_DIR = \"/kaggle/working/pdf_json\"\nQDRANT_DIR = \"/kaggle/working/qdrant_db\" \n\nos.makedirs(OUT_JSON_DIR, exist_ok=True)\nos.makedirs(QDRANT_DIR, exist_ok=True)\n\nQDRANT_PATH = os.path.join(QDRANT_DIR, \"qdrant_collection\")\nprint(\"Cek\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T06:01:37.658435Z","iopub.execute_input":"2025-08-22T06:01:37.659175Z","iopub.status.idle":"2025-08-22T06:01:37.663761Z","shell.execute_reply.started":"2025-08-22T06:01:37.659147Z","shell.execute_reply":"2025-08-22T06:01:37.663061Z"}},"outputs":[{"name":"stdout","text":"Cek\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!ls -R /kaggle/input\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T06:01:40.424092Z","iopub.execute_input":"2025-08-22T06:01:40.424794Z","iopub.status.idle":"2025-08-22T06:01:40.564069Z","shell.execute_reply.started":"2025-08-22T06:01:40.424769Z","shell.execute_reply":"2025-08-22T06:01:40.563333Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input:\nmy-pdfs\n\n/kaggle/input/my-pdfs:\n'Interpretable Machine Learning for COVID-19 An Empirical Study on Severity Prediction Task.pdf'\n Xie_Oriented_R-CNN_for_Object_Detection_ICCV_2021_paper.pdf\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ============================================================\n# 4. Ekstraksi PDF (teks, tabel, gambar + OCR) - FIXED\n# ============================================================\ndef extract_pdf(pdf_path, out_json_dir=OUT_JSON_DIR, image_ocr=True):\n    doc = fitz.open(pdf_path)\n    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n\n    data = {\"pages\": []}\n\n    for page_num in range(len(doc)):\n        page = doc[page_num]\n        text = page.get_text(\"text\")\n\n        # OCR halaman jika teks terlalu sedikit\n        if len(text.strip()) < 30:\n            pix = page.get_pixmap()\n            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n            text += \"\\n\" + pytesseract.image_to_string(img)\n\n        page_data = {\n            \"page_number\": page_num + 1,\n            \"text\": text.strip(),\n            \"tables\": [],\n            \"images\": []\n        }\n\n        # Ekstrak tabel dengan pdfplumber\n        with pdfplumber.open(pdf_path) as plumber_pdf:\n            plumber_page = plumber_pdf.pages[page_num]\n            for table in plumber_page.find_tables():\n                rows = table.extract()\n                page_data[\"tables\"].append({\n                    \"bbox\": table.bbox,\n                    \"rows\": rows\n                })\n\n        # Ekstrak gambar + OCR - FIXED\n        for img_index, img in enumerate(page.get_images(full=True)):\n            xref = img[0]\n            base_image = doc.extract_image(xref)\n            img_bytes = base_image[\"image\"]\n            img_ext = base_image[\"ext\"]\n            \n            # FIX: Convert to bytes instead of bytearray\n            img_bytes_obj = bytes(img_bytes)\n            \n            # Create in-memory file-like object\n            from io import BytesIO\n            img_buffer = BytesIO(img_bytes_obj)\n            \n            try:\n                img_pil = Image.open(img_buffer)\n                \n                ocr_text = \"\"\n                if image_ocr:\n                    try:\n                        ocr_text = pytesseract.image_to_string(img_pil)\n                    except Exception as e:\n                        print(f\"OCR error: {e}\")\n                        ocr_text = \"\"\n                \n                page_data[\"images\"].append({\n                    \"bbox\": img[1],\n                    \"width\": base_image.get(\"width\"),\n                    \"height\": base_image.get(\"height\"),\n                    \"ext\": img_ext,\n                    \"ocr_text\": ocr_text.strip()\n                })\n                \n            except Exception as e:\n                print(f\"Error processing image: {e}\")\n                # Still add image info even if processing failed\n                page_data[\"images\"].append({\n                    \"bbox\": img[1],\n                    \"width\": base_image.get(\"width\"),\n                    \"height\": base_image.get(\"height\"),\n                    \"ext\": img_ext,\n                    \"ocr_text\": f\"Error processing image: {str(e)}\"\n                })\n\n        data[\"pages\"].append(page_data)\n\n    # Simpan ke JSON\n    out_path = os.path.join(out_json_dir, f\"{pdf_name}.json\")\n    with open(out_path, \"w\", encoding=\"utf-8\") as fp:\n        json.dump(data, fp, indent=2, ensure_ascii=False)\n\n    print(f\"✅ Ekstraksi selesai: {pdf_path} -> {out_path}\")\n    return out_path\n\nprint(\"Done Fixed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T06:01:43.375921Z","iopub.execute_input":"2025-08-22T06:01:43.376614Z","iopub.status.idle":"2025-08-22T06:01:43.388151Z","shell.execute_reply.started":"2025-08-22T06:01:43.376580Z","shell.execute_reply":"2025-08-22T06:01:43.387309Z"}},"outputs":[{"name":"stdout","text":"Done Fixed\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install regex langdetect\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T06:02:02.719785Z","iopub.execute_input":"2025-08-22T06:02:02.720618Z","iopub.status.idle":"2025-08-22T06:02:05.930925Z","shell.execute_reply.started":"2025-08-22T06:02:02.720570Z","shell.execute_reply":"2025-08-22T06:02:05.929937Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\nRequirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (1.0.9)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import regex as re\nfrom langdetect import detect\nimport unicodedata\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T06:02:10.723328Z","iopub.execute_input":"2025-08-22T06:02:10.723573Z","iopub.status.idle":"2025-08-22T06:02:10.727290Z","shell.execute_reply.started":"2025-08-22T06:02:10.723556Z","shell.execute_reply":"2025-08-22T06:02:10.726599Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def advanced_clean_text(text):\n    # Unicode Normalization (NFKC)\n    text = unicodedata.normalize('NFKC', text)\n\n    # De-hyphenation\n    text = re.sub(r'-\\n', '', text)\n\n    # Remove line breaks & multiple spaces\n    text = re.sub(r'\\n+', '\\n', text)\n    text = re.sub(r'[ \\t]+', ' ', text)\n\n    # Remove boilerplate: hapus baris pendek <5 karakter\n    lines = text.split('\\n')\n    lines = [line for line in lines if len(line.strip()) > 5]\n    text = \"\\n\".join(lines)\n\n    return text.strip()\n\nprint(\"Advanced Prepocess\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T06:02:12.880055Z","iopub.execute_input":"2025-08-22T06:02:12.880356Z","iopub.status.idle":"2025-08-22T06:02:12.885783Z","shell.execute_reply.started":"2025-08-22T06:02:12.880334Z","shell.execute_reply":"2025-08-22T06:02:12.885068Z"}},"outputs":[{"name":"stdout","text":"Advanced Prepocess\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ============================================================\n#\n# ============================================================\ndef json_to_documents(json_path):\n    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n        \n    pdf_name = os.path.splitext(os.path.basename(json_path))[0]\n\n    docs = []\n    for page in data[\"pages\"]:\n        text_parts = [advanced_clean_text(page[\"text\"])]\n\n        # Tambahkan tabel sebagai markdown - FIXED\n        for tbl in page[\"tables\"]:\n            # FIX: Handle None values in table rows\n            cleaned_rows = []\n            for r in tbl[\"rows\"]:\n                if r:  # hanya proses row yang tidak empty\n                    # Convert semua cell ke string, handle None\n                    cleaned_cells = [str(cell) if cell is not None else \"\" for cell in r]\n                    cleaned_rows.append(\" | \".join(cleaned_cells))\n            \n            if cleaned_rows:\n                tbl_text = \"\\n\".join(cleaned_rows)\n                text_parts.append(f\"TABLE:\\n{tbl_text}\")\n\n        # Tambahkan OCR gambar\n        for img in page[\"images\"]:\n            if img.get(\"ocr_text\"):\n                text_parts.append(f\"IMAGE OCR:\\n{img['ocr_text']}\")\n\n        combined = \"\\n\".join(text_parts).strip()\n        if combined:\n            try:\n                lang = detect(combined)\n            except:\n                lang = \"unknown\"\n\n            docs.append(Document(\n    page_content=combined,\n    metadata={\n        \"document_id\": f\"{pdf_name}_page_{page['page_number']}\",\n        \"source\": os.path.basename(json_path),\n        \"file_type\": \"pdf\",\n        \"created_at\": datetime.now().isoformat(),\n        \"schema\": \"v1\",\n        \"knowledge_type\": \"research_paper\",  # atau lainnya\n        \"role_retention\": \"permanent\",\n        \"page\": page[\"page_number\"],\n        \"lang\": lang,\n        \"has_tables\": len(page[\"tables\"]) > 0,\n        \"has_images\": len(page[\"images\"]) > 0\n    }\n))\n    return docs\n\n\nprint(\"============================================================\")\nprint(\" 6. Convert JSON ke LangChain Document & Chunking - FIXED .3\")\nprint(\"============================================================\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T06:30:27.624839Z","iopub.execute_input":"2025-08-22T06:30:27.625159Z","iopub.status.idle":"2025-08-22T06:30:27.634937Z","shell.execute_reply.started":"2025-08-22T06:30:27.625135Z","shell.execute_reply":"2025-08-22T06:30:27.634356Z"}},"outputs":[{"name":"stdout","text":"============================================================\n 6. Convert JSON ke LangChain Document & Chunking - FIXED .3\n============================================================\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"print(\"============================================================\")\nprint(\"7. Chunking + Embedding + Qdrant (Mengganti FAISS) - FIXED.3\")\nprint(\"============================================================\")\n\ndef process_documents(docs, qdrant_path=QDRANT_PATH, chunk_size=800, overlap=120):\n    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n    chunks = splitter.split_documents(docs)\n\n    # Gunakan model yang lebih kecil dan cepat\n    embeddings = HuggingFaceEmbeddings(\n        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"  # Lebih cepat\n    )\n\n    # Buat Qdrant vector store\n    vs = Qdrant.from_documents(\n        chunks,\n        embeddings,\n        path=qdrant_path,  # Local path untuk Qdrant\n        collection_name=\"pdf_documents\",\n        force_recreate=True,  # Buat collection baru setiap kali\n        wait = True,\n        timeout=60\n    )\n\n    print(f\"✅ Qdrant vectorstore saved di {qdrant_path}\")\n    return vs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T06:18:31.945284Z","iopub.execute_input":"2025-08-22T06:18:31.945566Z","iopub.status.idle":"2025-08-22T06:18:31.951240Z","shell.execute_reply.started":"2025-08-22T06:18:31.945546Z","shell.execute_reply":"2025-08-22T06:18:31.950530Z"}},"outputs":[{"name":"stdout","text":"============================================================\n7. Chunking + Embedding + Qdrant (Mengganti FAISS) - FIXED.3\n============================================================\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"print(\"============================================================\")\nprint(\"8. Review hasil ekstraksi (cek JSON & VectorDB) - FIXED.3\")\nprint(\"============================================================\")\n\ndef review_extraction(json_path):\n    print(f\"\\n=== REVIEW EXTRACTION: {os.path.basename(json_path)} ===\")\n    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    \n    print(f\"Jumlah halaman: {len(data['pages'])}\")\n    \n    for page in data[\"pages\"]:  # Review hanya 2 halaman pertama\n        print(f\"\\n📄 Halaman {page['page_number']}\")\n        print(f\"Teks ({len(page['text'])} chars): {page['text'][:200]}...\")\n        \n        if page[\"tables\"]:\n            print(f\"Jumlah tabel: {len(page['tables'])}\")\n            for i, tbl in enumerate(page[\"tables\"][:1]):  # Review hanya tabel pertama\n                print(f\"  Tabel {i+1}:\")\n                for j, row in enumerate(tbl[\"rows\"][:3]):  # Review hanya 3 baris pertama\n                    # FIX: Handle None values in table cells\n                    cleaned_row = [str(cell) if cell is not None else \"\" for cell in row]\n                    print(f\"    Baris {j+1}: {' | '.join(cleaned_row)}\")\n                if len(tbl[\"rows\"]) > 3:\n                    print(\"    ...\")\n        \n        if page[\"images\"]:\n            print(f\"Jumlah gambar: {len(page['images'])}\")\n            for i, img in enumerate(page[\"images\"][:1]):  # Review hanya gambar pertama\n                print(f\"  Gambar {i+1}: {img.get('width', '?')}x{img.get('height', '?')}\")\n                if img.get(\"ocr_text\"):\n                    print(f\"    OCR: {img['ocr_text'][:100]}...\")\n\ndef check_json(out_json_dir=OUT_JSON_DIR):\n    print(\"\\n=== REVIEW JSON FILES ===\")\n    for f in os.listdir(out_json_dir):\n        if f.endswith(\".json\"):\n            path = os.path.join(out_json_dir, f)\n            with open(path, \"r\", encoding=\"utf-8\") as fp:\n                data = json.load(fp)\n            print(f\"\\n📄 File: {f}\")\n            print(f\"Jumlah halaman: {len(data['pages'])}\")\n            for page in data[\"pages\"][:1]:  # tampilkan contoh halaman 1\n                print(f\" Halaman {page['page_number']}\")\n                print(\"  Teks:\", page[\"text\"][:200], \"...\")\n                if page[\"tables\"]:\n                    # FIX: Handle None values in table display\n                    first_table = page[\"tables\"][0]\n                    if first_table[\"rows\"]:\n                        first_row = [str(cell) if cell is not None else \"\" for cell in first_table[\"rows\"][0]]\n                        print(\"  Tabel contoh:\", \" | \".join(first_row))\n                if page[\"images\"]:\n                    print(\"  OCR Gambar contoh:\", page[\"images\"][0].get(\"ocr_text\", \"\")[:100])\n\ndef check_vectorstore(qdrant_path=QDRANT_PATH):\n    print(\"\\n=== REVIEW QDRANT VECTORSTORE ===\")\n    try:\n        # Gunakan SINGLE client instance\n        client = QdrantClient(path=qdrant_path)\n        \n        # Beri waktu untuk sync\n        import time\n        time.sleep(1)\n        \n        # Check collection info\n        collection_info = client.get_collection(\"pdf_documents\")\n        print(f\"✅ Collection status: {collection_info.status}\")\n        \n        # Count vectors\n        count_result = client.count(\n            collection_name=\"pdf_documents\",\n            exact=True\n        )\n        print(f\"✅ Vectors count: {count_result.count}\")\n        \n        client.close()\n        \n    except Exception as e:\n        print(f\"Error: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T06:19:56.710888Z","iopub.execute_input":"2025-08-22T06:19:56.711516Z","iopub.status.idle":"2025-08-22T06:19:56.723964Z","shell.execute_reply.started":"2025-08-22T06:19:56.711492Z","shell.execute_reply":"2025-08-22T06:19:56.723153Z"}},"outputs":[{"name":"stdout","text":"============================================================\n8. Review hasil ekstraksi (cek JSON & VectorDB) - FIXED.3\n============================================================\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Tambahkan di awal pipeline untuk reset\nimport shutil\n\n# Hapus folder Qdrant lama jika ada\nif os.path.exists(QDRANT_DIR):\n    shutil.rmtree(QDRANT_DIR)\n    print(\"🧹 Cleaned previous Qdrant storage\")\n\nos.makedirs(QDRANT_DIR, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T06:31:55.602385Z","iopub.execute_input":"2025-08-22T06:31:55.602701Z","iopub.status.idle":"2025-08-22T06:31:55.607981Z","shell.execute_reply.started":"2025-08-22T06:31:55.602677Z","shell.execute_reply":"2025-08-22T06:31:55.607234Z"}},"outputs":[{"name":"stdout","text":"🧹 Cleaned previous Qdrant storage\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# ============================================================\n# 9. Main Pipeline dengan Qdrant - FIXED\n# ============================================================\nprint(\"============================================================\")\nprint(\"9. Main Pipeline dengan Qdrant - FIXED\")\nprint(\"============================================================\")\n\n# Clean previous storage\nif os.path.exists(QDRANT_DIR):\n    shutil.rmtree(QDRANT_DIR)\n    print(\"🧹 Cleaned previous Qdrant storage\")\nos.makedirs(QDRANT_DIR, exist_ok=True)\n\npdf_files = [os.path.join(PDF_DIR, f) for f in os.listdir(PDF_DIR) if f.endswith(\".pdf\")]\n\nfor pdf in pdf_files:\n    print(f\"\\n🔧 Processing: {os.path.basename(pdf)}\")\n    json_path = extract_pdf(pdf)\n    review_extraction(json_path)\n    docs = json_to_documents(json_path)\n    process_documents(docs)  # ✅ Tidak ada concurrent access lagi\n\n# Cek hasil ekstraksi\ncheck_json()\ncheck_vectorstore()  # ✅ Hanya satu client yang dibuka\n\nprint(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T06:31:57.517734Z","iopub.execute_input":"2025-08-22T06:31:57.518005Z","iopub.status.idle":"2025-08-22T06:32:23.681728Z","shell.execute_reply.started":"2025-08-22T06:31:57.517986Z","shell.execute_reply":"2025-08-22T06:32:23.681041Z"}},"outputs":[{"name":"stdout","text":"============================================================\n9. Main Pipeline dengan Qdrant - FIXED\n============================================================\n🧹 Cleaned previous Qdrant storage\n\n🔧 Processing: Xie_Oriented_R-CNN_for_Object_Detection_ICCV_2021_paper.pdf\n✅ Ekstraksi selesai: /kaggle/input/my-pdfs/Xie_Oriented_R-CNN_for_Object_Detection_ICCV_2021_paper.pdf -> /kaggle/working/pdf_json/Xie_Oriented_R-CNN_for_Object_Detection_ICCV_2021_paper.json\n\n=== REVIEW EXTRACTION: Xie_Oriented_R-CNN_for_Object_Detection_ICCV_2021_paper.json ===\nJumlah halaman: 10\n\n📄 Halaman 1\nTeks (3508 chars): Oriented R-CNN for Object Detection\nXingxing Xie\nGong Cheng*\nJiabao Wang\nXiwen Yao\nJunwei Han\nSchool of Automation, Northwestern Ploytechnical University, Xi’an, China\n{xiexing,jbwang}@mail.nwpu.edu.c...\nJumlah gambar: 1\n  Gambar 1: 3940x920\n    OCR: 54 anchors Oriented 2 anchors Horizontal Oriented 3 anchors Oriented\n8 0°6 proposals proposals propo...\n\n📄 Halaman 2\nTeks (5917 chars): To push the envelope further: we investigate why the\nefficiency of region proposal-based oriented detectors has\ntrailed thus far.\nOur observation is that the main obsta-\ncle impeding the speed of prop...\n\n📄 Halaman 3\nTeks (3442 chars): Figure 2: Overall framework of oriented R-CNN, which is a two-stage detector built on FPN. The first stage generates\noriented proposals by oriented RPN and the second stage is oriented R-CNN head to c...\nJumlah gambar: 1\n  Gambar 1: 3460x1975\n    OCR: ist stage Oriented RPN\n\n   \n\n \n\n     \n  \n\n1x1 Conv Decoding\nHxWx256 HxWx6A\n7\nPa (x, y,w,h, Aa, AB)\n7...\n\n📄 Halaman 4\nTeks (4982 chars): Figure 3: Illustration of midpoint offset representation. (a)\nThe schematic diagram of midpoint offset representation.\n(b) An example of midpoint offset representation.\nin the representation of orient...\nJumlah gambar: 2\n  Gambar 1: 1740x1030\n\n📄 Halaman 5\nTeks (4940 chars): Figure 5: Illustration of the process of rotated RoIAlign.\nBlue box is a parallelogram proposal generated by oriented\nRPN, and the most-left red box is its corresponding rectan-\ngular proposal used fo...\nJumlah gambar: 1\n  Gambar 1: 1825x715\n\n📄 Halaman 6\nTeks (964 chars): Figure 6: Proposals generated by oriented RPN on the DOTA dataset. The top-200 proposals per image are displayed.\nFigure 7: Examples of detection results on the DOTA dataset using oriented R-CNN with ...\nJumlah tabel: 1\n  Tabel 1:\n    Baris 1: Method | R300 | R1000 | R2000\n    Baris 2: OrientedRPN | 81.60 | 92.20 | 92.80\nJumlah gambar: 2\n  Gambar 1: 3730x1475\n    OCR: ie WEEE,\n\nSe eee\n\n \n\na...\n\n📄 Halaman 7\nTeks (4725 chars): Figure 8: Examples of detection results on the HRSC2016 dataset using oriented R-CNN with R-50-FPN backbone. The\noriented bounding boxes whose scores are higher than 0.3 are shown.\nMethod\nBackbone\nPL\n...\nJumlah tabel: 1\n  Tabel 1:\n    Baris 1: Method | Backbone | PL | BD | BR | GTF | SV | LV | SH | TC | BC | ST | SBF | RA | HA | SP | HC | mAP\n    Baris 2: One-stage |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | \n    Baris 3: RetinaNet-O†\nDRN[28]\nR3Det[39]\nPIoU[4]\nRSDet[30]\nDAL[27]\nS2ANet[12] | R-50-FPN\nH-104\nR-101-FPN\nDLA-34\nR-101-FPN\nR-50-FPN\nR-50-FPN | 88.67\n88.91\n88.76\n80.90\n89.80\n88.68\n89.11 | 77.62\n80.22\n83.09\n69.70\n82.90\n76.55\n82.84 | 41.81\n43.52\n50.91\n24.10\n48.60\n45.08\n48.37 | 58.17\n63.35\n67.27\n60.20\n65.20\n66.80\n71.11 | 74.58\n73.48\n76.23\n38.30\n69.50\n67.00\n78.11 | 71.64\n70.69\n80.39\n64.40\n70.10\n76.76\n78.39 | 79.11\n84.94\n86.72\n64.80\n70.20\n79.74\n87.25 | 90.29\n90.14\n90.78\n90.90\n90.50\n90.84\n90.83 | 82.18\n83.85\n84.68\n77.20\n85.60\n79.54\n84.90 | 74.32\n84.11\n83.24\n70.40\n83.40\n78.45\n85.64 | 54.75\n50.12\n61.98\n46.50\n62.50\n57.71\n60.36 | 60.60\n58.41\n61.35\n37.10\n63.90\n62.27\n62.60 | 62.57\n67.62\n66.91\n57.10\n65.60\n69.05\n65.26 | 69.67\n68.60\n70.63\n61.90\n67.20\n73.14\n69.13 | 60.64\n52.50\n53.94\n64.00\n68.00\n60.11\n57.94 | 68.43\n70.70\n73.79\n60.50\n72.20\n71.44\n74.12\n    ...\nJumlah gambar: 1\n  Gambar 1: 3905x970\n\n📄 Halaman 8\nTeks (3921 chars): Method\nBackbone\nmAP(07)\nmAP(12)\nPIoU [4]\nDLA-34\n89.20\n-\nDRN [28]\nH-34\n-\n92.70\nR3Det [39]\nR-101-FPN\n89.26\n96.01\nDAL [27]\nR-101-FPN\n89.77\n-\nS2ANet [12]\nR-101-FPN\n90.17\n95.01\nRotated RPN [26]\nR-101\n79.08...\nJumlah tabel: 2\n  Tabel 1:\n    Baris 1: Method | Backbone | mAP(07) | mAP(12)\n    Baris 2: PIoU[4]\nDRN[28]\nR3Det[39]\nDAL[27]\nS2ANet[12]\nRotatedRPN[26]\nR2CNN[17]\nRoITransformer[7]\nGlidingVertex[37]\nCenterMap-Net[35]\nOrientedR-CNN\nOrientedR-CNN | DLA-34\nH-34\nR-101-FPN\nR-101-FPN\nR-101-FPN\nR-101\nR-101\nR-101-FPN\nR-101-FPN\nR-50-FPN\nR-50-FPN\nR-101-FPN | 89.20\n-\n89.26\n89.77\n90.17\n79.08\n73.07\n86.20\n88.20\n-\n90.40\n90.50 | -\n92.70\n96.01\n-\n95.01\n85.64\n79.73\n-\n-\n92.80\n96.50\n97.60\nJumlah gambar: 1\n  Gambar 1: 1315x1360\n    OCR: mAP(%)\n\n@ Oriented R-CNN ral Rol Transformer*\n\ninl Faster R-CNN-Ot ® RetinaNet-O' As’net\n76\n74\n72\n\n7...\n\n📄 Halaman 9\nTeks (5795 chars): References\n[1] Seyed Majid Azimi, Eleonora Vig, Reza Bahmanyar, Marco\nK¨orner, and Peter Reinartz. Towards multi-class object de-\ntection in unconstrained remote sensing imagery.\nIn Pro-\nceedings of t...\n\n📄 Halaman 10\nTeks (4940 chars): [27] Qi Ming, Zhiqiang Zhou, Lingjuan Miao, Hongwei Zhang,\nand Linhao Li.\nDynamic anchor learning for arbitrary-\noriented object detection. In Proceedings of the AAAI Con-\nference on Artificial Intell...\n✅ Qdrant vectorstore saved di /kaggle/working/qdrant_db/qdrant_collection\n\n🔧 Processing: Interpretable Machine Learning for COVID-19 An Empirical Study on Severity Prediction Task.pdf\n✅ Ekstraksi selesai: /kaggle/input/my-pdfs/Interpretable Machine Learning for COVID-19 An Empirical Study on Severity Prediction Task.pdf -> /kaggle/working/pdf_json/Interpretable Machine Learning for COVID-19 An Empirical Study on Severity Prediction Task.json\n\n=== REVIEW EXTRACTION: Interpretable Machine Learning for COVID-19 An Empirical Study on Severity Prediction Task.json ===\nJumlah halaman: 14\n\n📄 Halaman 1\nTeks (6311 chars): JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. 00, NO. 0, MONTH 2020\n1\nInterpretable Machine Learning for COVID-19: An\nEmpirical Study on Severity Prediction Task\nHan Wu, Wenjie Ruan, J...\n\n📄 Halaman 2\nTeks (4010 chars): 2\nJOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. 00, NO. 0, MONTH 2020\nFig. 1: The difference between the usual workﬂow of machine learning, and our approach.\nBesides, several model-agn...\nJumlah gambar: 1\n  Gambar 1: 1775x860\n    OCR: —@—©O—6~ &\n\nComputer Diagnosis\n\nDataset\n\nTraining High Accuracy Black-Box Model\n\nModel Interpretatio...\n\n📄 Halaman 3\nTeks (6028 chars): HAN. WU et al.: INTERPRETABLE MACHINE LEARNING FOR COVID-19: AN EMPIRICAL STUDY ON SEVERITY PREDICTION TASK\n3\nAccumulated Local Effects:\nAccumulated Local Effects\n(ALE) averages the changes in the pre...\n\n📄 Halaman 4\nTeks (5196 chars): 4\nJOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. 00, NO. 0, MONTH 2020\n1) There is strong correlation between cTnICKMBOrdinal1\nand cTnICKMBOrdinal2 because they are the same test\namong ...\n\n📄 Halaman 5\nTeks (2763 chars): HAN. WU et al.: INTERPRETABLE MACHINE LEARNING FOR COVID-19: AN EMPIRICAL STUDY ON SEVERITY PREDICTION TASK\n5\n(a) Decision Tree\n(b) Random Forest\n(c) Gradient Boosted Trees\n(d) Neural Networks\nFig. 2:...\nJumlah gambar: 4\n  Gambar 1: 720x432\n    OCR: Partial dependence\n\n2\na\n\n2\na\n\n2\na\n\n2\nN\n\n@ 2000 4000 6000 8000\nNTproBNP\n\n100\nCRP2\n\n150...\n\n📄 Halaman 6\nTeks (717 chars): 6\nJOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. 00, NO. 0, MONTH 2020\n(a) Decision Tree\n(b) Random Forest\n(c) Gradient Boosted Trees\n(d) Neural Networks\nFig. 3: Individual Conditional ...\nJumlah gambar: 8\n  Gambar 1: 693x344\n    OCR: ALE\n\nas\no6\na4\na2\noo\n0.2\n-0.4\n0.6\n-0.8\n\n—— normal\n—— severe\n\n© 2000 4000 6000 8000\nNTproBNP\n\n \n\n100\nC...\n\n📄 Halaman 7\nTeks (5058 chars): HAN. WU et al.: INTERPRETABLE MACHINE LEARNING FOR COVID-19: AN EMPIRICAL STUDY ON SEVERITY PREDICTION TASK\n7\nE. Misclassiﬁed Patients\nEven though the most important features revealed by our\nmodels ex...\n\n📄 Halaman 8\nTeks (5510 chars): 8\nJOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. 00, NO. 0, MONTH 2020\n1) Doctors’ Diagnoses: We present the test results of both\npatients to doctors without indicating which patient is...\n\n📄 Halaman 9\nTeks (749 chars): HAN. WU et al.: INTERPRETABLE MACHINE LEARNING FOR COVID-19: AN EMPIRICAL STUDY ON SEVERITY PREDICTION TASK\n9\n(a) Decision Tree\n(b) Random Forests\n(c) Gradient Boosted Trees\n(d) Neural Networks\nFig. 5...\nJumlah gambar: 8\n  Gambar 1: 601x271\n    OCR: NTproBNP > 311.00\nHemoptysis=False\n8.60 < CRP2 <= 33.25\nTemp <= 36.60\nHeadache=False\n\n   \n\n \n\nCancer...\n\n📄 Halaman 10\nTeks (726 chars): 10\nJOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. 00, NO. 0, MONTH 2020\n(a) Decision Tree\n(b) Random Forests\n(c) Gradient Boosted Trees\n(d) Neural Networks\nFig. 7: LIME Explanation (Fal...\nJumlah gambar: 8\n  Gambar 1: 601x271\n    OCR: NTproBNP > 311.00\n\nCRP2 > 33.25\ncTnICKMBOrdinall <= 0.00\n36.90 < ALB1 «<:\n\n   \n\nHeadache=False\n\nLoca...\n\n📄 Halaman 11\nTeks (4558 chars): HAN. WU et al.: INTERPRETABLE MACHINE LEARNING FOR COVID-19: AN EMPIRICAL STUDY ON SEVERITY PREDICTION TASK\n11\nIV. VALIDATION ON OTHER DATASETS\nAt the initial outbreak of the pandemic, our research\nle...\nJumlah gambar: 1\n  Gambar 1: 488x430\n    OCR: Num: 351\n\nLDH <365 Ur\"\n\nNo\n\n       \n       \n  \n \n  \n\nYes\n\n   \n\nNum: 202\nhs-CRP < 41.2 mg\n\n   \n\n1\nNo\n...\n\n📄 Halaman 12\nTeks (3215 chars): 12\nJOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. 00, NO. 0, MONTH 2020\n(a) Decision Tree\n(b) Random Forests\n(c) Gradient Boosted Trees\n(d) Neural Networks\nFig. 10: LIME Explanation (Ka...\nJumlah gambar: 4\n  Gambar 1: 543x271\n    OCR: Local explanation for class positive\nLeukocytes <= -0.64\nEosinophils <= -0.62\n\nPlatelets <= -0.61\n\nH...\n\n📄 Halaman 13\nTeks (2088 chars): HAN. WU et al.: INTERPRETABLE MACHINE LEARNING FOR COVID-19: AN EMPIRICAL STUDY ON SEVERITY PREDICTION TASK\n13\nAPPENDIX\nTABLE XVII: Diagnoses\nFeature\nComments\nSeverity03\nSevere (3) - Normal (0)\nSeveri...\n\n📄 Halaman 14\nTeks (7616 chars): 14\nJOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. 00, NO. 0, MONTH 2020\nREFERENCES\n[1] T. Singhal, “A review of coronavirus disease-2019 (covid-19),” The\nIndian Journal of Pediatrics, v...\n✅ Qdrant vectorstore saved di /kaggle/working/qdrant_db/qdrant_collection\n\n=== REVIEW JSON FILES ===\n\n📄 File: Xie_Oriented_R-CNN_for_Object_Detection_ICCV_2021_paper.json\nJumlah halaman: 10\n Halaman 1\n  Teks: Oriented R-CNN for Object Detection\nXingxing Xie\nGong Cheng*\nJiabao Wang\nXiwen Yao\nJunwei Han\nSchool of Automation, Northwestern Ploytechnical University, Xi’an, China\n{xiexing,jbwang}@mail.nwpu.edu.c ...\n  OCR Gambar contoh: 54 anchors Oriented 2 anchors Horizontal Oriented 3 anchors Oriented\n8 0°6 proposals proposals propo\n\n📄 File: Interpretable Machine Learning for COVID-19 An Empirical Study on Severity Prediction Task.json\nJumlah halaman: 14\n Halaman 1\n  Teks: JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. 00, NO. 0, MONTH 2020\n1\nInterpretable Machine Learning for COVID-19: An\nEmpirical Study on Severity Prediction Task\nHan Wu, Wenjie Ruan, J ...\n\n=== REVIEW QDRANT VECTORSTORE ===\n✅ Collection status: green\n✅ Vectors count: 94\nDone\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"def search_documents(query, k=3):\n    \"\"\"Search dalam vectorstore\"\"\"\n    embeddings = HuggingFaceEmbeddings(\n        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n    )\n    \n    vs = Qdrant(\n        client=QdrantClient(path=QDRANT_PATH),\n        collection_name=\"pdf_documents\", \n        embeddings=embeddings\n    )\n    \n    results = vs.similarity_search(query, k=k)\n    \n    print(f\"🔍 Results for: '{query}'\\n\")\n    for i, doc in enumerate(results):\n        print(f\"📄 Result {i+1} (Page {doc.metadata['page']}):\")\n        print(f\"   {doc.page_content[:150]}...\")\n        print(\"-\" * 80)\n\n# Test search\nsearch_documents(\"object detection\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T06:21:32.037680Z","iopub.execute_input":"2025-08-22T06:21:32.037952Z","iopub.status.idle":"2025-08-22T06:21:33.182299Z","shell.execute_reply.started":"2025-08-22T06:21:32.037935Z","shell.execute_reply":"2025-08-22T06:21:33.181469Z"}},"outputs":[{"name":"stdout","text":"🔍 Results for: 'object detection'\n\n📄 Result 1 (Page 1):\n   convolutional neural network (CNN) model can discriminates\nCOVID-19 from Non-COVID-19 using chest CT image [9].\nIt achieves interpretability through g...\n--------------------------------------------------------------------------------\n📄 Result 2 (Page 4):\n   fine-tuned parameters, gradient boosting can result in better\nperformance than random forests. Still, it is tough for humans\nto interpret a sequence o...\n--------------------------------------------------------------------------------\n📄 Result 3 (Page 1):\n   various heterogeneous feature groups as input and outputs\nan equidimensional embedding corresponding to each feature\ngroup. The DeepFM [5] module comp...\n--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":25}]}