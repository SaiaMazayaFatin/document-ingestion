{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d461bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0779ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b5bd2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3384f83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "from transformers import pipeline as hf_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cfd1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39878808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import (\n",
    "    create_engine, Table, Column, Text, Integer, TIMESTAMP,\n",
    "    JSON, MetaData, ARRAY\n",
    ")\n",
    "from sqlalchemy.dialects.postgresql import JSONB\n",
    "from sqlalchemy.engine import Engine\n",
    "from datetime import datetime, timezone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87663e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c80f74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    # Models\n",
    "    stt_model: str = \"openai/whisper-small\"\n",
    "    embed_model: str = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "    clean_llm_model: str = \"gpt-4o-mini\"\n",
    "    extract_llm_model: str = \"gpt-4o-mini\"\n",
    "\n",
    "    # Audio\n",
    "    sample_rate: int = 16000\n",
    "    window_seconds: int = 30\n",
    "    loudness_target_lufs: float = -23.0  # placeholder (demo)\n",
    "    do_vad: bool = True  # placeholder (demo)\n",
    "\n",
    "    # Paths\n",
    "    audio_folder: str = \"./raw_data/audio\"\n",
    "\n",
    "    # Vector DB (Qdrant)\n",
    "    qdrant_url: str = os.getenv(\"QDRANT_URL\", \"http://localhost:6333\")\n",
    "    qdrant_api_key: str = os.getenv(\"QDRANT_API_KEY\", None)\n",
    "    qdrant_collection: str = \"rag_main\"\n",
    "    qdrant_vector_size: int = 1024\n",
    "    qdrant_distance: str = \"Cosine\"\n",
    "\n",
    "    # Graph DB (Neo4j)\n",
    "    neo4j_url: str = os.getenv(\"NEO4J_URL\", \"bolt://localhost:7687\")\n",
    "    neo4j_user: str = os.getenv(\"NEO4J_USER\", \"neo4j\")\n",
    "    neo4j_password: str = os.getenv(\"NEO4J_PASSWORD\", \"password\")\n",
    "\n",
    "    # SQL (Postgres)\n",
    "    pg_url: str = os.getenv(\"PG_URL\", \"postgresql+psycopg2://postgres:postgres@localhost:5432/ragdb\")\n",
    "\n",
    "    # OpenAI\n",
    "    openai_api_key: str = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "CFG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02424e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_sql_engine() -> Engine:\n",
    "    engine = create_engine(CFG.pg_url, future=True)\n",
    "    return engine\n",
    "\n",
    "def init_sql_schema(engine: Engine):\n",
    "    metadata = MetaData()\n",
    "\n",
    "    documents = Table(\n",
    "        \"documents\", metadata,\n",
    "        Column(\"doc_id\", Text, primary_key=True),\n",
    "        Column(\"title\", Text),\n",
    "        Column(\"language\", Text),\n",
    "        Column(\"source\", Text),\n",
    "        Column(\"file\", Text),\n",
    "        Column(\"author\", Text),\n",
    "        Column(\"created_at\", TIMESTAMP(timezone=True)),\n",
    "        Column(\"knowledge_tags\", ARRAY(Text)),\n",
    "        Column(\"role_restriction\", ARRAY(Text)),\n",
    "        Column(\"lineage\", JSONB),\n",
    "    )\n",
    "\n",
    "    chunks = Table(\n",
    "        \"chunks\", metadata,\n",
    "        Column(\"chunk_id\", Text, primary_key=True),\n",
    "        Column(\"doc_id\", Text),\n",
    "        Column(\"segments\", JSONB),\n",
    "        Column(\"token_estimate\", Integer),\n",
    "        Column(\"created_at\", TIMESTAMP(timezone=True)),\n",
    "        Column(\"text\", Text),\n",
    "    )\n",
    "\n",
    "    vdb_refs = Table(\n",
    "        \"vdb_refs\", metadata,\n",
    "        Column(\"chunk_id\", Text, primary_key=True),\n",
    "        Column(\"collection\", Text),\n",
    "        Column(\"vector_dim\", Integer),\n",
    "        Column(\"inserted_at\", TIMESTAMP(timezone=True)),\n",
    "    )\n",
    "\n",
    "    gdb_triples = Table(\n",
    "        \"gdb_triples\", metadata,\n",
    "        Column(\"triple_id\", Text, primary_key=True),\n",
    "        Column(\"s\", Text), Column(\"p\", Text), Column(\"o\", Text),\n",
    "        Column(\"doc_id\", Text), Column(\"chunk_id\", Text),\n",
    "        Column(\"confidence\", Integer),\n",
    "        Column(\"created_at\", TIMESTAMP(timezone=True)),\n",
    "    )\n",
    "\n",
    "    metadata.create_all(engine)\n",
    "    return {\"documents\": documents, \"chunks\": chunks, \"vdb_refs\": vdb_refs, \"gdb_triples\": gdb_triples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0051bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_qdrant() -> QdrantClient:\n",
    "    client = QdrantClient(url=CFG.qdrant_url, api_key=CFG.qdrant_api_key)\n",
    "    # Ensure collection exists\n",
    "    exists = False\n",
    "    try:\n",
    "        info = client.get_collection(CFG.qdrant_collection)\n",
    "        exists = info is not None\n",
    "    except Exception:\n",
    "        exists = False\n",
    "\n",
    "    if not exists:\n",
    "        client.recreate_collection(\n",
    "            collection_name=CFG.qdrant_collection,\n",
    "            vectors_config=VectorParams(\n",
    "                size=CFG.qdrant_vector_size,\n",
    "                distance=Distance.COSINE\n",
    "            )\n",
    "        )\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f43661b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_neo4j_driver():\n",
    "    driver = GraphDatabase.driver(CFG.neo4j_url, auth=(CFG.neo4j_user, CFG.neo4j_password))\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee058fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_llm():\n",
    "    return ChatOpenAI(model=CFG.clean_llm_model, temperature=0, api_key=CFG.openai_api_key)\n",
    "\n",
    "def get_extract_llm():\n",
    "    return ChatOpenAI(model=CFG.extract_llm_model, temperature=0, api_key=CFG.openai_api_key)\n",
    "\n",
    "def get_embeddings():\n",
    "    # Qwen3-Embedding-0.6B via HF\n",
    "    return HuggingFaceEmbeddings(model_name=CFG.embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d877e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_to_16k_mono(in_path: str, out_path: str):\n",
    "    y, sr = librosa.load(in_path, sr=None, mono=True)\n",
    "    y16 = librosa.resample(y, orig_sr=sr, target_sr=CFG.sample_rate)\n",
    "    sf.write(out_path, y16, CFG.sample_rate)\n",
    "\n",
    "def split_audio_30s(path_16k: str) -> List[str]:\n",
    "    audio = AudioSegment.from_file(path_16k)\n",
    "    # Ensure mono 16k\n",
    "    audio = audio.set_channels(1).set_frame_rate(CFG.sample_rate)\n",
    "    chunk_len_ms = CFG.window_seconds * 1000\n",
    "    chunks = []\n",
    "    for i in range(0, len(audio), chunk_len_ms):\n",
    "        part = audio[i:i+chunk_len_ms]\n",
    "        out = f\"{path_16k}.{i//chunk_len_ms:02d}.wav\"\n",
    "        part.export(out, format=\"wav\", parameters=[\"-ac\", \"1\", \"-ar\", str(CFG.sample_rate)])\n",
    "        chunks.append(out)\n",
    "    return chunks\n",
    "\n",
    "def stt_whisper_batch(chunk_paths: List[str], language: str|None=None) -> List[Dict[str, Any]]:\n",
    "    # HuggingFace pipeline for ASR\n",
    "    asr = hf_pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=CFG.stt_model,\n",
    "        chunk_length_s=None,  # we already split at 30s\n",
    "        return_timestamps=True\n",
    "    )\n",
    "    results = []\n",
    "    for p in chunk_paths:\n",
    "        if language:\n",
    "            out = asr(p, generate_kwargs={\"language\": language})\n",
    "        else:\n",
    "            out = asr(p)\n",
    "        results.append({\"file\": p, \"text\": out[\"text\"], \"chunks\": out.get(\"chunks\")})\n",
    "    return results\n",
    "\n",
    "def merge_segments_text(stt_results: List[Dict[str, Any]]) -> str:\n",
    "    return \"\\n\".join([r[\"text\"].strip() for r in stt_results if r.get(\"text\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82cf4e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CLEAN_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a professional text cleaner. \"\n",
    "     \"Given raw ASR transcript, remove fillers, fix casing/punctuation, \"\n",
    "     \"preserve meaning, do not hallucinate. Keep technical terms.\"),\n",
    "    (\"user\", \"Raw transcript:\\n\\n{raw}\\n\\nReturn the cleaned transcript.\")\n",
    "])\n",
    "\n",
    "clean_chain = CLEAN_PROMPT | get_clean_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2504f1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_chunks(text: str, doc_id: str, file_name: str, language: str) -> List[Document]:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1200,\n",
    "        chunk_overlap=180,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    )\n",
    "    pieces = splitter.split_text(text)\n",
    "    docs = []\n",
    "    now = datetime.now(timezone.utc)\n",
    "    for idx, t in enumerate(pieces, start=1):\n",
    "        docs.append(Document(\n",
    "            page_content=t,\n",
    "            metadata={\n",
    "                \"chunk_id\": f\"ch_{doc_id}_{idx:02d}\",\n",
    "                \"doc_id\": doc_id,\n",
    "                \"file\": file_name,\n",
    "                \"source\": \"audio_ingestion\",\n",
    "                \"language\": language,\n",
    "                \"role_restriction\": [\"public_read\"],\n",
    "                \"created_at\": now.isoformat(),\n",
    "            }\n",
    "        ))\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0ff5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_qdrant(client: QdrantClient, docs: List[Document], embeddings: HuggingFaceEmbeddings):\n",
    "    vs = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=CFG.qdrant_collection,\n",
    "        embeddings=embeddings,\n",
    "    )\n",
    "    vs.add_documents(docs)\n",
    "    return vs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "541519d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity(BaseModel):\n",
    "    name: str\n",
    "    aliases: List[str] = Field(default_factory=list)\n",
    "\n",
    "class Triple(BaseModel):\n",
    "    s: str\n",
    "    p: str\n",
    "    o: str\n",
    "    confidence: float\n",
    "\n",
    "class ExtractionResult(BaseModel):\n",
    "    entities: List[Entity]\n",
    "    triples: List[Triple]\n",
    "\n",
    "EXTRACT_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are an information extraction system for RAG indexing. \"\n",
    "     \"Extract key entities (canonical names + aliases) and relation triples \"\n",
    "     \"(subject, predicate, object) from the text. \"\n",
    "     \"Use domain-agnostic simple predicates (uses, queries, requires, includes, mitigates, etc.). \"\n",
    "     \"Return only facts present in the text. Confidence 0.0-1.0.\"),\n",
    "    (\"user\", \"Text:\\n\\n{chunk}\\n\\nReturn structured JSON.\")\n",
    "])\n",
    "\n",
    "# LCEL structured output\n",
    "extract_chain = EXTRACT_PROMPT | get_extract_llm().with_structured_output(ExtractionResult)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "419c0965",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_MERGE = \"\"\"\n",
    "MERGE (s:Entity {name: $s})\n",
    "MERGE (o:Entity {name: $o})\n",
    "MERGE (s)-[r:REL {predicate: $p}]->(o)\n",
    "ON CREATE SET r.provenance = [{doc_id: $doc_id, chunk_id: $chunk_id}],\n",
    "              r.confidence = $confidence,\n",
    "              r.created_at = datetime()\n",
    "ON MATCH SET  r.provenance = coalesce(r.provenance, []) + {doc_id: $doc_id, chunk_id: $chunk_id},\n",
    "              r.confidence = CASE WHEN r.confidence < $confidence THEN $confidence ELSE r.confidence END\n",
    "\"\"\"\n",
    "\n",
    "def upsert_neo4j(driver, triples: List[Triple], doc_id: str, chunk_id: str):\n",
    "    with driver.session() as s:\n",
    "        for t in triples:\n",
    "            if t.confidence < 0.8:\n",
    "                continue\n",
    "            s.run(NEO4J_MERGE, s=t.s, p=t.p, o=t.o,\n",
    "                  doc_id=doc_id, chunk_id=chunk_id, confidence=t.confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed64be81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_document(engine: Engine, documents_tbl, doc: Dict[str, Any]):\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(documents_tbl.insert().values(**doc))\n",
    "\n",
    "def insert_chunk(engine: Engine, chunks_tbl, row: Dict[str, Any]):\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(chunks_tbl.insert().values(**row))\n",
    "\n",
    "def insert_vdb_ref(engine: Engine, vdb_tbl, chunk_id: str, dim: int):\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(vdb_tbl.insert().values(\n",
    "            chunk_id=chunk_id, collection=CFG.qdrant_collection, vector_dim=dim, inserted_at=datetime.now(timezone.utc)\n",
    "        ))\n",
    "\n",
    "def insert_triple(engine: Engine, gdb_tbl, tri: Triple, doc_id: str, chunk_id: str):\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(gdb_tbl.insert().values(\n",
    "            triple_id=str(uuid.uuid4()),\n",
    "            s=tri.s, p=tri.p, o=tri.o,\n",
    "            doc_id=doc_id, chunk_id=chunk_id,\n",
    "            confidence=int(tri.confidence * 100),\n",
    "            created_at=datetime.now(timezone.utc)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2afe75e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipeState(TypedDict):\n",
    "    doc_id: str\n",
    "    title: str\n",
    "    language: str\n",
    "    file_path: str\n",
    "    file_name: str\n",
    "    transcript_raw_segments: List[Dict[str, Any]]\n",
    "    transcript_full: str\n",
    "    transcript_clean: str\n",
    "    chunks: List[Document]\n",
    "    extraction: Dict[str, Any]\n",
    "\n",
    "def node_preprocess_audio(state: PipeState) -> PipeState:\n",
    "    # resample to 16k mono\n",
    "    out16 = f\"{state['file_path']}.16k.wav\"\n",
    "    resample_to_16k_mono(state[\"file_path\"], out16)\n",
    "    state[\"file_path\"] = out16\n",
    "    return state\n",
    "\n",
    "def node_stt(state: PipeState) -> PipeState:\n",
    "    parts = split_audio_30s(state[\"file_path\"])\n",
    "    stt_results = stt_whisper_batch(parts, language=state[\"language\"] if state[\"language\"] else None)\n",
    "    state[\"transcript_raw_segments\"] = stt_results\n",
    "    state[\"transcript_full\"] = merge_segments_text(stt_results)\n",
    "    return state\n",
    "\n",
    "def node_clean(state: PipeState) -> PipeState:\n",
    "    cleaned = clean_chain.invoke({\"raw\": state[\"transcript_full\"]})\n",
    "    # cleaned bisa berupa str (ChatModel) → pastikan type\n",
    "    state[\"transcript_clean\"] = cleaned if isinstance(cleaned, str) else str(cleaned)\n",
    "    return state\n",
    "\n",
    "def node_chunk(state: PipeState) -> PipeState:\n",
    "    docs = to_chunks(\n",
    "        text=state[\"transcript_clean\"],\n",
    "        doc_id=state[\"doc_id\"],\n",
    "        file_name=state[\"file_name\"],\n",
    "        language=state[\"language\"] or \"auto\",\n",
    "    )\n",
    "    state[\"chunks\"] = docs\n",
    "    return state\n",
    "\n",
    "def node_persist_sql_docs_chunks(state: PipeState) -> PipeState:\n",
    "    engine = init_sql_engine()\n",
    "    tables = init_sql_schema(engine)\n",
    "    # documents\n",
    "    doc_row = {\n",
    "        \"doc_id\": state[\"doc_id\"],\n",
    "        \"title\": state[\"title\"],\n",
    "        \"language\": state[\"language\"] or \"auto\",\n",
    "        \"source\": \"audio_ingestion\",\n",
    "        \"file\": state[\"file_name\"],\n",
    "        \"author\": \"narrator\",\n",
    "        \"created_at\": datetime.now(timezone.utc),\n",
    "        \"knowledge_tags\": [\"RAG\",\"LLM\",\"retrieval\",\"vector_database\",\"best_practices\"],\n",
    "        \"role_restriction\": [\"public_read\"],\n",
    "        \"lineage\": {\n",
    "            \"stt_model\": CFG.stt_model,\n",
    "            \"preclean_llm\": CFG.clean_llm_model,\n",
    "            \"embed_model\": CFG.embed_model,\n",
    "            \"audio_window\": f\"{CFG.window_seconds}s\"\n",
    "        }\n",
    "    }\n",
    "    insert_document(engine, tables[\"documents\"], doc_row)\n",
    "\n",
    "    # chunks\n",
    "    for d in state[\"chunks\"]:\n",
    "        row = {\n",
    "            \"chunk_id\": d.metadata[\"chunk_id\"],\n",
    "            \"doc_id\": d.metadata[\"doc_id\"],\n",
    "            \"segments\": [\"auto_topic\"],  # placeholder; bisa diisi jika ada partitioning tematik\n",
    "            \"token_estimate\": len(d.page_content.split()),\n",
    "            \"created_at\": datetime.now(timezone.utc),\n",
    "            \"text\": d.page_content\n",
    "        }\n",
    "        insert_chunk(engine, tables[\"chunks\"], row)\n",
    "\n",
    "    return state\n",
    "\n",
    "def node_vector_index(state: PipeState) -> PipeState:\n",
    "    qclient = init_qdrant()\n",
    "    embs = get_embeddings()\n",
    "    upsert_qdrant(qclient, state[\"chunks\"], embs)\n",
    "\n",
    "    # persist vdb refs in SQL\n",
    "    engine = init_sql_engine()\n",
    "    tables = init_sql_schema(engine)\n",
    "    for d in state[\"chunks\"]:\n",
    "        insert_vdb_ref(engine, tables[\"vdb_refs\"], d.metadata[\"chunk_id\"], CFG.qdrant_vector_size)\n",
    "    return state\n",
    "\n",
    "def node_extract_graph(state: PipeState) -> PipeState:\n",
    "    # run extraction per chunk (you could batch; here sequential for clarity)\n",
    "    results: List[Tuple[Document, ExtractionResult]] = []\n",
    "    for d in state[\"chunks\"]:\n",
    "        res = extract_chain.invoke({\"chunk\": d.page_content})\n",
    "        results.append((d, res))\n",
    "\n",
    "    # persist to Neo4j & SQL\n",
    "    driver = init_neo4j_driver()\n",
    "    engine = init_sql_engine()\n",
    "    tables = init_sql_schema(engine)\n",
    "\n",
    "    for d, res in results:\n",
    "        # Neo4j upsert\n",
    "        upsert_neo4j(driver, res.triples, doc_id=d.metadata[\"doc_id\"], chunk_id=d.metadata[\"chunk_id\"])\n",
    "        # SQL triples (audit/provenance)\n",
    "        for tri in res.triples:\n",
    "            if tri.confidence >= 0.8:\n",
    "                insert_triple(engine, tables[\"gdb_triples\"], tri, d.metadata[\"doc_id\"], d.metadata[\"chunk_id\"])\n",
    "\n",
    "    # store in state (optional)\n",
    "    state[\"extraction\"] = {\n",
    "        \"total_chunks\": len(results),\n",
    "        \"total_triples\": sum(len(r.triples) for _, r in results)\n",
    "    }\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "281b2ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph():\n",
    "    g = StateGraph(PipeState)\n",
    "    g.add_node(\"preprocess_audio\", node_preprocess_audio)\n",
    "    g.add_node(\"stt\", node_stt)\n",
    "    g.add_node(\"clean\", node_clean)\n",
    "    g.add_node(\"chunk\", node_chunk)\n",
    "    g.add_node(\"persist_sql_docs_chunks\", node_persist_sql_docs_chunks)\n",
    "    g.add_node(\"vector_index\", node_vector_index)\n",
    "    g.add_node(\"extract_graph\", node_extract_graph)\n",
    "\n",
    "    g.set_entry_point(\"preprocess_audio\")\n",
    "    g.add_edge(\"preprocess_audio\", \"stt\")\n",
    "    g.add_edge(\"stt\", \"clean\")\n",
    "    g.add_edge(\"clean\", \"chunk\")\n",
    "    g.add_edge(\"chunk\", \"persist_sql_docs_chunks\")\n",
    "    g.add_edge(\"persist_sql_docs_chunks\", \"vector_index\")\n",
    "    g.add_edge(\"vector_index\", \"extract_graph\")\n",
    "    g.add_edge(\"extract_graph\", END)\n",
    "    return g.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a04a6b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_doc_state(file_path: str, language: str|None):\n",
    "    return PipeState(\n",
    "        doc_id=f\"doc_{uuid.uuid4().hex[:8]}\",\n",
    "        title=os.path.splitext(os.path.basename(file_path))[0],\n",
    "        language=language or \"auto\",\n",
    "        file_path=file_path,\n",
    "        file_name=os.path.basename(file_path),\n",
    "        transcript_raw_segments=[],\n",
    "        transcript_full=\"\",\n",
    "        transcript_clean=\"\",\n",
    "        chunks=[],\n",
    "        extraction={}\n",
    "    )\n",
    "\n",
    "def discover_audio_files(folder: str) -> List[Tuple[str, str]]:\n",
    "    # Return list[(path, language_hint)]\n",
    "    # Example assumption: file names contain _en/_id\n",
    "    outs = []\n",
    "    for name in os.listdir(folder):\n",
    "        if not name.lower().endswith((\".wav\", \".mp3\", \".m4a\")):\n",
    "            continue\n",
    "        lang = \"en\" if \"_en\" in name.lower() else (\"id\" if \"_id\" in name.lower() else None)\n",
    "        outs.append((os.path.join(folder, name), lang))\n",
    "    return outs\n",
    "\n",
    "def main():\n",
    "    # Prepare DBs / clients once to fail fast if misconfig\n",
    "    _ = init_qdrant()\n",
    "    _ = init_neo4j_driver()\n",
    "    _engine = init_sql_engine()\n",
    "    _ = init_sql_schema(_engine)\n",
    "\n",
    "    graph = build_graph()\n",
    "\n",
    "    files = discover_audio_files(CFG.audio_folder)\n",
    "    if not files:\n",
    "        print(\"No audio files found in ./ingest/audio. Put your files there (e.g., *_en.wav, *_id.wav).\")\n",
    "        return\n",
    "\n",
    "    for fpath, lang in files:\n",
    "        print(f\"Processing: {fpath} (lang={lang or 'auto'})\")\n",
    "        state = new_doc_state(fpath, lang)\n",
    "        final = graph.invoke(state)\n",
    "        print(\"Done:\", final[\"doc_id\"], final.get(\"extraction\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "feff5d46",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 28\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Prepare DBs / clients once to fail fast if misconfig\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43minit_qdrant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     _ \u001b[38;5;241m=\u001b[39m init_neo4j_driver()\n\u001b[0;32m     30\u001b[0m     _engine \u001b[38;5;241m=\u001b[39m init_sql_engine()\n",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m, in \u001b[0;36minit_qdrant\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m exists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqdrant_collection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     exists \u001b[38;5;241m=\u001b[39m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\qdrant_client\\qdrant_client.py:2223\u001b[0m, in \u001b[0;36mQdrantClient.get_collection\u001b[1;34m(self, collection_name, **kwargs)\u001b[0m\n\u001b[0;32m   2213\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get detailed information about specified existing collection\u001b[39;00m\n\u001b[0;32m   2214\u001b[0m \n\u001b[0;32m   2215\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2219\u001b[0m \u001b[38;5;124;03m    Detailed information about the collection\u001b[39;00m\n\u001b[0;32m   2220\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2221\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\qdrant_client\\qdrant_remote.py:2584\u001b[0m, in \u001b[0;36mQdrantRemote.get_collection\u001b[1;34m(self, collection_name, **kwargs)\u001b[0m\n\u001b[0;32m   2577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefer_grpc:\n\u001b[0;32m   2578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GrpcToRest\u001b[38;5;241m.\u001b[39mconvert_collection_info(\n\u001b[0;32m   2579\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrpc_collections\u001b[38;5;241m.\u001b[39mGet(\n\u001b[0;32m   2580\u001b[0m             grpc\u001b[38;5;241m.\u001b[39mGetCollectionInfoRequest(collection_name\u001b[38;5;241m=\u001b[39mcollection_name),\n\u001b[0;32m   2581\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m   2582\u001b[0m         )\u001b[38;5;241m.\u001b[39mresult\n\u001b[0;32m   2583\u001b[0m     )\n\u001b[1;32m-> 2584\u001b[0m result: Optional[types\u001b[38;5;241m.\u001b[39mCollectionInfo] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollections_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\n\u001b[0;32m   2586\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult\n\u001b[0;32m   2587\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet collection returned None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\qdrant_client\\http\\api\\collections_api.py:320\u001b[0m, in \u001b[0;36mSyncCollectionsApi.get_collection\u001b[1;34m(self, collection_name)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_collection\u001b[39m(\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    315\u001b[0m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m m\u001b[38;5;241m.\u001b[39mInlineResponse2005:\n\u001b[0;32m    317\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    Get detailed information about specified existing collection\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_for_get_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\qdrant_client\\http\\api\\collections_api.py:144\u001b[0m, in \u001b[0;36m_CollectionsApi._build_for_get_collection\u001b[1;34m(self, collection_name)\u001b[0m\n\u001b[0;32m    139\u001b[0m path_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollection_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(collection_name),\n\u001b[0;32m    141\u001b[0m }\n\u001b[0;32m    143\u001b[0m headers \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInlineResponse2005\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/collections/\u001b[39;49m\u001b[38;5;132;43;01m{collection_name}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:95\u001b[0m, in \u001b[0;36mApiClient.request\u001b[1;34m(self, type_, method, url, path_params, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     94\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mbuild_request(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:112\u001b[0m, in \u001b[0;36mApiClient.send\u001b[1;34m(self, request, type_)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: Request, type_: Type[T]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m--> 112\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmiddleware\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_inner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n\u001b[0;32m    115\u001b[0m         retry_after_s \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetry-After\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:250\u001b[0m, in \u001b[0;36mBaseMiddleware.__call__\u001b[1;34m(self, request, call_next)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: Request, call_next: Send) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:134\u001b[0m, in \u001b[0;36mApiClient.send_inner\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_inner\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: Request) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 134\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ResponseHandlingException(e)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1011\u001b[0m     )\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    248\u001b[0m )\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    259\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\httpcore\\_sync\\connection.py:78\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_lock:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m         stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m         ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m         http2_negotiated \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     82\u001b[0m             ssl_object \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     83\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m ssl_object\u001b[38;5;241m.\u001b[39mselected_alpn_protocol() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     84\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\httpcore\\_sync\\connection.py:124\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhost\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_origin\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_origin\u001b[38;5;241m.\u001b[39mport,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocket_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket_options,\n\u001b[0;32m    122\u001b[0m     }\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnect_tcp\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m--> 124\u001b[0m         stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m         trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\site-packages\\httpcore\\_backends\\sync.py:208\u001b[0m, in \u001b[0;36mSyncBackend.connect_tcp\u001b[1;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[0;32m    202\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    203\u001b[0m     socket\u001b[38;5;241m.\u001b[39mtimeout: ConnectTimeout,\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[0;32m    205\u001b[0m }\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m--> 208\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m option \u001b[38;5;129;01min\u001b[39;00m socket_options:\n\u001b[0;32m    214\u001b[0m         sock\u001b[38;5;241m.\u001b[39msetsockopt(\u001b[38;5;241m*\u001b[39moption)  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\study_ai\\Lib\\socket.py:855\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m error \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_errors:\n\u001b[1;32m--> 855\u001b[0m         \u001b[43mexceptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclear\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# raise only the last error\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     exceptions\u001b[38;5;241m.\u001b[39mappend(exc)\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e12b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
